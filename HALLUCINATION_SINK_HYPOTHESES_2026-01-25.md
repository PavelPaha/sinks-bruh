# Hypotheses: Attention Sinks ↔ Hallucinations (2026-01-25)

## Контекст

Хочется сфокусироваться на основном тейке: **паттерны sink-attention связаны с галлюцинациями**.  
Ниже — аккуратные формулировки и “paper-style” проверки, чтобы не размывать понятия и не обещать лишнего.

---

## Операциональные определения (чтобы не спорить словами)

### Что такое “галлюцинация” в экспериментах

Нужно привязать “hallucination” к измеряемой метке.

#### Вариант A (рекомендуется для старта): TruthfulQA

- Берём TruthfulQA в формате multiple-choice (если используем MC) или scoring-метку “truthful”.
- **hallucinated = 1**, если ответ **неправильный/неправдивый** по метке.
- **hallucinated = 0**, если ответ **правильный/правдивый**.

#### Вариант B: Unanswerable QA

- Например, QA с “no-answer” / impossible questions.
- hallucinated = 1, если модель уверенно отвечает вместо “не знаю”.

Важно: в статье прямо написать, что “hallucination” = **ошибка на TruthfulQA (или аналогичной задаче)**, а не философское определение.

### Что такое sink mass (в общем виде)

Определяем как агрегат внимания на первые \(K\) позиций (sink window) при выборе набора query-позиций \(Q\):

\[
s(Q,K) = \frac{1}{|Q|}\sum_{i\in Q}\sum_{j=0}^{K-1}\bar{A}[i,j]
\]

Где \(\bar{A}\) — attention, усреднённый по слоям/головам (либо анализируется по слоям/головам отдельно).

**Базовый протокол:** \(Q=\{S-1\}\) (last-token), \(K=4\) (и абляции по \(K\)).

---

## Гипотезы (sink ↔ hallucination)

### H1 — Distribution shift: sink mass отличается на галлюцинациях

**Гипотеза:** при фиксированной модели/протоколе распределение `sink_mass` на `hallucinated=1` отличается от `hallucinated=0`.

**Тесты:**

- разница средних/медиан + bootstrap CI
- effect size (например Cohen’s d)
- визуализация: KDE/violin + доверительные интервалы

**Комментарий:** это “безопасная” гипотеза: не требует утверждать причинность.

### H2 — Predictive: sink mass предсказывает галлюцинации как классификатор

**Гипотеза:** `sink_mass` даёт ненулевую предсказательную силу для `hallucinated`.

**Метрики:**

- AUROC / AUPRC (особенно если классы несбалансированы)
- калибровка порога: FPR@TPR, etc.

**Базовая линия:** константный/случайный классификатор.

### H3 — Added value over entropy: sink ≠ просто “неуверенность”

**Гипотеза:** `sink_mass` даёт добавку к предсказанию галлюцинации **сверх** `entropy`.

**Формализация (минимально “paper-grade”):**

- модель A: `hallucinated ~ entropy`
- модель B: `hallucinated ~ entropy + sink_mass`
- сравнить log-loss / AUROC (bootstrap CI)

**Если B лучше A:** можно утверждать, что sink-сигнал не сводится к неопределённости.

### H4 — Localization: эффект локализован по слоям/головам

**Гипотеза:** разница sink-attention между hallucinated и non-hallucinated концентрируется:

- в определённых слоях (layerwise профиль),
- в ограниченном числе голов (headwise “спайки”).

**Тесты/визуализации:**

- per-layer: \(\Delta s_l = \mathbb{E}[s_l|halluc]-\mathbb{E}[s_l|\neg halluc]\)
- per-head heatmap \(\Delta s_{l,h}\)

**Профит:** это делает результат менее “корреляционным” и более механистичным.

---

## Обязательные абляции (чтобы не обвиняли в артефакте протокола)

- **Prompting / chat-template:** `chat=off` vs `chat=on` (первые токены могут быть системными спец-токенами)
- **Sink window \(K\):** \(K \in \{1,2,4,8\}\)
- **Query set \(Q\):** last-token vs tail-N (идея: ранние токены промпта “ещё без контекста”)

---

## Минимальный план “под статью” (MVP)

1) Выбрать датасет с операциональной меткой `hallucinated` (TruthfulQA MC/labels).
2) Посчитать `sink_mass`, `entropy`, `hallucinated` на 2–3 моделях разных семейств.
3) Проверить H1–H3 (H4 как бонус, если успеваем).
4) Зафиксировать, где меняется знак/сила эффекта при абляциях `chat/K/Q`.
