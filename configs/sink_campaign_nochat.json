{
  "task": "sink_h1_campaign_nochat",
  "defaults": {
    "samples_small": 2000,
    "samples_large": 1000,
    "large_threshold_b": 14,
    "sink_tokens": 4,
    "query_mode": "last",
    "chat": "off",
    "quant_small": "none",
    "quant_large": "4bit",
    "language_freshqa": "English",
    "seed": 42
  },
  "datasets": [
    { "task": "truthfulqa_mc", "split": "validation" },
    { "task": "halueval", "split": "test" },
    { "task": "freshqa_false_premise", "split": "test" },
    { "task": "mmlu", "split": "test" }
  ],
  "models": [
    "Qwen/Qwen2.5-0.5B-Instruct",
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "meta-llama/Llama-3.2-1B-Instruct",
    "Qwen/Qwen2.5-1.5B-Instruct",
    "openlm-research/open_llama_3b_v2",
    "EleutherAI/pythia-2.8b-deduped",
    "meta-llama/Llama-3.2-3B-Instruct",
    "google/gemma-2-2b-it",
    "microsoft/phi-2",
    "Qwen/Qwen2.5-7B-Instruct",
    "mistralai/Mistral-7B-Instruct-v0.3",
    "mistralai/Mistral-Nemo-Instruct-2407",
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "openlm-research/open_llama_7b_v2",
    "google/gemma-2-9b-it",
    "Qwen/Qwen2.5-14B-Instruct",
    "google/gemma-2-27b-it",
    "Qwen/Qwen2.5-32B-Instruct"
  ]
}

