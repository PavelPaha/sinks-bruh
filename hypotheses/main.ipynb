{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8929f07-07de-4707-8057-b135d3b4a9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:17:09.453178Z",
     "iopub.status.busy": "2026-01-27T22:17:09.452018Z",
     "iopub.status.idle": "2026-01-27T22:17:09.539296Z",
     "shell.execute_reply": "2026-01-27T22:17:09.538005Z",
     "shell.execute_reply.started": "2026-01-27T22:17:09.453138Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 22:12 .\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:33 ..\n",
      "-rw-r--r-- 1 jupyter jupyter  6148 Jan 27 21:10 .DS_Store\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:11 .ipynb_checkpoints\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:10 H0_sanity\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:11 H1_distribution_shift\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:11 H2_predictive\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:14 H3_added_value_entropy\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:14 H4_localization\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:14 H5_chat_sensitivity\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:14 H6_query_set_sensitivity\n",
      "-rw-r--r-- 1 jupyter jupyter  1172 Jan 27 21:10 README.md\n",
      "-rw-r--r-- 1 jupyter jupyter  3587 Jan 27 21:10 WORKFLOW.md\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:10 _TEMPLATE\n",
      "-rw-r--r-- 1 jupyter jupyter    51 Jan 27 21:10 __init__.py\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:22 __pycache__\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:10 _lib\n",
      "drwxr-xr-x 1 jupyter jupyter     0 Jan 27 21:10 hypotheses\n",
      "-rw-r--r-- 1 jupyter jupyter 19073 Jan 27 22:12 main.ipynb\n"
     ]
    }
   ],
   "source": [
    "!cd /home/jupyter/project\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f31731-d5cf-44f4-a1c8-58bb9714521f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:17:09.542048Z",
     "iopub.status.busy": "2026-01-27T22:17:09.540983Z",
     "iopub.status.idle": "2026-01-27T22:17:34.717745Z",
     "shell.execute_reply": "2026-01-27T22:17:34.715903Z",
     "shell.execute_reply.started": "2026-01-27T22:17:09.541999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /kernel/lib/python3.10/site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 25.5 MB/s  0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-25.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python3 -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python3 -m pip install --upgrade pip\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements-hypotheses.txt'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/usr/local/bin/python3', '-m', 'pip', 'install', '-r', 'requirements-hypotheses.txt']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7274/3555437647.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"install\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-U\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"install\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"requirements-hypotheses.txt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/usr/local/bin/python3', '-m', 'pip', 'install', '-r', 'requirements-hypotheses.txt']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"pip\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements-hypotheses.txt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fb24c-0126-4bdc-aff6-f18ae2442fef",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-27T22:10:00.956381Z",
     "iopub.status.idle": "2026-01-27T22:10:00.957104Z",
     "shell.execute_reply": "2026-01-27T22:10:00.956772Z",
     "shell.execute_reply.started": "2026-01-27T22:10:00.956743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys, subprocess\n",
    "\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"-U\",\n",
    "#     \"requests==2.32.5\",\n",
    "#     \"fsspec==2024.3.1\",          # <= 2024.3.1 для datasets==2.19.2\n",
    "#     \"huggingface_hub==0.23.5\",\n",
    "#     \"datasets==2.19.2\",\n",
    "#     \"transformers==4.44.2\",\n",
    "#     \"tokenizers==0.19.1\",\n",
    "#     \"accelerate==0.33.0\",\n",
    "#     \"safetensors==0.4.5\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4e16f-7f61-4036-8090-32f4b35e6a81",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-27T22:10:00.958528Z",
     "iopub.status.idle": "2026-01-27T22:10:00.959096Z",
     "shell.execute_reply": "2026-01-27T22:10:00.958850Z",
     "shell.execute_reply.started": "2026-01-27T22:10:00.958817Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys, subprocess\n",
    "\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"-U\",\n",
    "#     \"fsspec==2024.3.1\",\n",
    "#     \"s3fs==2024.3.1\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfcdeab-a8ff-457b-9ed7-43c456c3ca26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:51:09.470166Z",
     "iopub.status.busy": "2026-01-27T22:51:09.469001Z",
     "iopub.status.idle": "2026-01-27T22:52:36.969023Z",
     "shell.execute_reply": "2026-01-27T22:52:36.967897Z",
     "shell.execute_reply.started": "2026-01-27T22:51:09.470111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Downloading readme: 53.2kB [00:00, 68.1MB/s]\n",
      "Downloading metadata: 138kB [00:00, 211MB/s]\n",
      "Downloading data: 100%|██████████| 3.50M/3.50M [00:00<00:00, 7.33MB/s]\n",
      "Downloading data: 100%|██████████| 408k/408k [00:00<00:00, 1.57MB/s]\n",
      "Downloading data: 100%|██████████| 76.5k/76.5k [00:00<00:00, 425kB/s]\n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:00<00:00, 56.7MB/s]\n",
      "Generating test split: 100%|██████████| 14042/14042 [00:00<00:00, 26046.44 examples/s]\n",
      "Generating validation split: 100%|██████████| 1531/1531 [00:00<00:00, 13817.33 examples/s]\n",
      "Generating dev split: 100%|██████████| 285/285 [00:00<00:00, 10881.70 examples/s]\n",
      "Generating auxiliary_train split: 100%|██████████| 99842/99842 [00:05<00:00, 16959.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-0.5B-Instruct quantization=none device=cuda...\n",
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H0_sanity/data/mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.meta.json\n",
      "Prepared 100 valid examples (requested up to 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 100 examples to /home/jupyter/project/sinks/hypotheses/H0_sanity/data/mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 34.00%\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1/h1_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1_heatmap/heatmap_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/layers/layer_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/correlation/correlation_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1/h1_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/h1_heatmap/heatmap_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/layers/layer_grid_mmlu.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H0_sanity/plots/correlation/correlation_grid_mmlu.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H0_sanity/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H0_sanity/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3191dc-9f96-4020-b39d-00b16eeb2569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:19:28.966851Z",
     "iopub.status.busy": "2026-01-27T22:19:28.965396Z",
     "iopub.status.idle": "2026-01-27T22:24:21.790667Z",
     "shell.execute_reply": "2026-01-27T22:24:21.789512Z",
     "shell.execute_reply.started": "2026-01-27T22:19:28.966793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [02:15<00:00, 33.81s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:12<00:00, 18.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:36<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1/h1_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1_heatmap/heatmap_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1/h1_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H1_distribution_shift/plots/h1_heatmap/heatmap_grid_truthfulqa_mc.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H1_distribution_shift/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H1_distribution_shift/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bfada8-5467-4f6d-b795-0d57866dfe1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:26:30.314353Z",
     "iopub.status.busy": "2026-01-27T22:26:30.313322Z",
     "iopub.status.idle": "2026-01-27T22:28:49.883652Z",
     "shell.execute_reply": "2026-01-27T22:28:49.882539Z",
     "shell.execute_reply.started": "2026-01-27T22:26:30.314290Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 195.23it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H2_predictive/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:35<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H2_predictive/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H2_predictive/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H2_predictive/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b47bb3f-73bd-43ec-8a9b-09f2a2629e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:46:32.921757Z",
     "iopub.status.busy": "2026-01-27T22:46:32.921094Z",
     "iopub.status.idle": "2026-01-27T22:48:52.624767Z",
     "shell.execute_reply": "2026-01-27T22:48:52.623693Z",
     "shell.execute_reply.started": "2026-01-27T22:46:32.921724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 182.39it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H3_added_value_entropy/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:35<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H3_added_value_entropy/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H3_added_value_entropy/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H3_added_value_entropy/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4600570a-0a48-42fd-96df-69f229149cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:39:23.689079Z",
     "iopub.status.busy": "2026-01-27T22:39:23.688016Z",
     "iopub.status.idle": "2026-01-27T22:41:58.759583Z",
     "shell.execute_reply": "2026-01-27T22:41:58.758382Z",
     "shell.execute_reply.started": "2026-01-27T22:39:23.689043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 204.73it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:16<00:00, 19.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H4_localization/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:35<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H4_localization/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1/h1_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1_heatmap/heatmap_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1/h1_summary.csv\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1/h1_grid_truthfulqa_mc.png\n",
      "Saved /home/jupyter/project/sinks/hypotheses/H4_localization/plots/h1_heatmap/heatmap_grid_truthfulqa_mc.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H4_localization/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H4_localization/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "229b7bcb-1ae8-4583-8e7b-2a604395ee7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:41:58.762976Z",
     "iopub.status.busy": "2026-01-27T22:41:58.761564Z",
     "iopub.status.idle": "2026-01-27T22:44:15.494008Z",
     "shell.execute_reply": "2026-01-27T22:44:15.492919Z",
     "shell.execute_reply.started": "2026-01-27T22:41:58.762923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 201.99it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H5_chat_sensitivity/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:35<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H5_chat_sensitivity/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H5_chat_sensitivity/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H5_chat_sensitivity/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40567053-c9df-4fce-a978-96a1e3de48d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:44:15.495970Z",
     "iopub.status.busy": "2026-01-27T22:44:15.495302Z",
     "iopub.status.idle": "2026-01-27T22:46:32.905109Z",
     "shell.execute_reply": "2026-01-27T22:46:32.904080Z",
     "shell.execute_reply.started": "2026-01-27T22:44:15.495922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model=Qwen/Qwen2.5-7B-Instruct quantization=none device=cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 202.86it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:14<00:00, 18.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run meta to /home/jupyter/project/sinks/hypotheses/H6_query_set_sensitivity/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.meta.json\n",
      "Prepared 415 valid examples (requested up to 500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/415 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 415/415 [00:35<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 415 examples to /home/jupyter/project/sinks/hypotheses/H6_query_set_sensitivity/data/truthfulqa_mc__Qwen__Qwen2.5-7B-Instruct__K4__qlast.jsonl.gz\n",
      "Accuracy: 79.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "os.chdir(\"/home/jupyter/project/sinks\")\n",
    "\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H6_query_set_sensitivity/scripts/run_all.py\", \"--measure\"])\n",
    "subprocess.check_call([sys.executable, \"hypotheses/H6_query_set_sensitivity/scripts/run_all.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e9afb-0fe7-47e7-a00f-6b7af060e141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
