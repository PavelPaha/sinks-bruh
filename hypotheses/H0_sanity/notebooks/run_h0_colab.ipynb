{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# H0 Sanity Check ‚Äî Colab GPU (one-click)\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏** –¥–µ–ª–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω:\n",
        "\n",
        "- —á–∏—Å—Ç—ã–π `git clone` —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏)\n",
        "- —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "- –∑–∞–ø—É—Å–∫ `scripts/measure_sink_text.py`\n",
        "- –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ (`scripts/plot_*.py`)\n",
        "- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ + `manifest.json` + `pip_freeze.txt`\n",
        "\n",
        "## –í–∞–∂–Ω–æ –ø—Ä–æ –ø—É—Ç–∏\n",
        "Colab runtime **–Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞** –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É `/Users/...`.\n",
        "\n",
        "–ß—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã \"–ø–æ—è–≤–ª—è–ª–∏—Å—å —É —Ç–µ–±—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –±–µ–∑ —Ä—É—á–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è\", –≤–∫–ª—é—á–∏ `USE_DRIVE = True` (cell 1):\n",
        "- –≤—ã–≤–æ–¥ –±—É–¥–µ—Ç –ø–∏—Å–∞—Ç—å—Å—è –≤ `Google Drive/MyDrive/sinks_runs/<RUN_NAME>/...`\n",
        "- —ç—Ç–æ—Ç –∫–∞—Ç–∞–ª–æ–≥ –º–æ–∂–Ω–æ —Å–∏–Ω–∫–∞—Ç—å –Ω–∞ Mac —á–µ—Ä–µ–∑ Google Drive app –∏ —à–∞—Ä–∏—Ç—å –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–æ—Ä—É.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3786853211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mOUT_BASE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/{DRIVE_SUBDIR}/{RUN_NAME}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# CONFIG + (optional) Google Drive + fresh clone\n",
        "#\n",
        "# –í–∞–∂–Ω–æ: Colab runtime –ù–ï –≤–∏–¥–∏—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –≤–∏–¥–∞ /Users/... .\n",
        "# –ß—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã \"–ø–æ—è–≤–∏–ª–∏—Å—å —É —Ç–µ–±—è –ª–æ–∫–∞–ª—å–Ω–æ –±–µ–∑ —Ä—É—á–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è\",\n",
        "# —Å–æ—Ö—Ä–∞–Ω—è–π –∏—Ö –≤ Google Drive (–æ–Ω —Å–∏–Ω–∫–∞–µ—Ç—Å—è –Ω–∞ —Ç–≤–æ—ë–º Mac —á–µ—Ä–µ–∑ Google Drive app).\n",
        "\n",
        "USE_DRIVE = True  # False -> —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ /content –∏ –≤ –∫–æ–Ω—Ü–µ –∫–∞—á–∞–µ–º zip\n",
        "DRIVE_SUBDIR = \"sinks_runs\"  # MyDrive/<DRIVE_SUBDIR>/<RUN_NAME>/...\n",
        "RUN_NAME = \"H0__mmlu__Qwen2.5-0.5B-Instruct__K4__qlast__N100__seed42\"\n",
        "\n",
        "REPO_URL = \"https://github.com/PavelPaha/sinks-bruh.git\"\n",
        "REPO_DIR = \"/content/sinks_repo\"\n",
        "\n",
        "TASK = \"mmlu\"\n",
        "SPLIT = \"test\"\n",
        "MODEL = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "SAMPLES = 100\n",
        "SEED = 42\n",
        "SINK_TOKENS = 4\n",
        "QUERY_MODE = \"last\"  # last | range\n",
        "QUERY_START = 0\n",
        "CHAT = \"auto\"  # auto | on | off\n",
        "DEVICE = \"cuda\"  # cuda | cpu\n",
        "QUANT = \"none\"  # none | 4bit | 8bit\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "    OUT_BASE = Path(f\"/content/drive/MyDrive/{DRIVE_SUBDIR}/{RUN_NAME}\")\n",
        "else:\n",
        "    OUT_BASE = Path(f\"/content/{DRIVE_SUBDIR}/{RUN_NAME}\")\n",
        "\n",
        "DATA_DIR = OUT_BASE / \"data\"\n",
        "PLOTS_DIR = OUT_BASE / \"plots\"\n",
        "META_DIR = OUT_BASE / \"meta\"\n",
        "for d in (DATA_DIR, PLOTS_DIR, META_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"OUT_BASE:\", OUT_BASE)\n",
        "\n",
        "# Fresh clone (reproducibility: clean repo state)\n",
        "repo_path = Path(REPO_DIR)\n",
        "if repo_path.exists():\n",
        "    shutil.rmtree(repo_path)\n",
        "\n",
        "subprocess.check_call([\"git\", \"clone\", REPO_URL, REPO_DIR])\n",
        "\n",
        "# Move into repo\n",
        "%cd /content/sinks_repo\n",
        "\n",
        "GIT_HEAD = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
        "print(\"Repo:\", Path.cwd())\n",
        "print(\"Git HEAD:\", GIT_HEAD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "CUDA version: 12.6\n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'sinks'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 69 (delta 12), reused 66 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 9.65 MiB | 16.66 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/sinks/sinks/sinks\n"
          ]
        }
      ],
      "source": [
        "# Install repo deps (reproducible) + tiny extras\n",
        "# We install from pyproject.toml (editable), then add missing runtime deps if any.\n",
        "\n",
        "!pip install -q -U pip\n",
        "!pip install -q -e .\n",
        "\n",
        "# measure_sink_text.py uses tqdm explicitly\n",
        "!pip install -q tqdm\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "!python -c \"import torch, transformers, datasets; print('torch', torch.__version__); print('transformers', transformers.__version__); print('datasets', datasets.__version__)\"\n",
        "\n",
        "# Save environment snapshot for collaborators\n",
        "!pip freeze > \"${META_DIR}/pip_freeze.txt\"\n",
        "(Path(META_DIR) / \"git_head.txt\").write_text(GIT_HEAD + \"\\n\", encoding=\"utf-8\")\n",
        "print(\"Saved:\", META_DIR / \"pip_freeze.txt\")\n",
        "print(\"Saved:\", META_DIR / \"git_head.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STDOUT:\n",
            "Loading model=Qwen/Qwen2.5-0.5B-Instruct quantization=none device=cuda...\n",
            "Saved run meta to hypotheses/H0_sanity/data/mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.meta.json\n",
            "Prepared 100 valid examples (requested up to 100).\n",
            "Done. Wrote 100 examples to hypotheses/H0_sanity/data/mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz\n",
            "Accuracy: 34.00%\n",
            "\n",
            "\n",
            "STDERR:\n",
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'cais/mmlu' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-27 20:02:46.229912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769544166.248706    5450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769544166.253887    5450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769544166.267514    5450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769544166.267532    5450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769544166.267535    5450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769544166.267538    5450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-27 20:02:46.271574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\n",
            "  1%|          | 1/100 [00:00<00:37,  2.63it/s]\n",
            "  3%|‚ñé         | 3/100 [00:00<00:13,  7.10it/s]\n",
            "  6%|‚ñå         | 6/100 [00:00<00:07, 11.77it/s]\n",
            "  9%|‚ñâ         | 9/100 [00:00<00:06, 14.79it/s]\n",
            " 11%|‚ñà         | 11/100 [00:00<00:05, 16.07it/s]\n",
            " 14%|‚ñà‚ñç        | 14/100 [00:01<00:04, 17.38it/s]\n",
            " 16%|‚ñà‚ñå        | 16/100 [00:01<00:04, 17.54it/s]\n",
            " 18%|‚ñà‚ñä        | 18/100 [00:01<00:04, 17.60it/s]\n",
            " 20%|‚ñà‚ñà        | 20/100 [00:01<00:04, 18.17it/s]\n",
            " 22%|‚ñà‚ñà‚ñè       | 22/100 [00:01<00:04, 17.75it/s]\n",
            " 25%|‚ñà‚ñà‚ñå       | 25/100 [00:01<00:03, 19.01it/s]\n",
            " 27%|‚ñà‚ñà‚ñã       | 27/100 [00:01<00:03, 19.19it/s]\n",
            " 30%|‚ñà‚ñà‚ñà       | 30/100 [00:01<00:03, 19.28it/s]\n",
            " 33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [00:02<00:03, 19.63it/s]\n",
            " 35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [00:02<00:03, 19.68it/s]\n",
            " 37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [00:02<00:03, 19.09it/s]\n",
            " 39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [00:02<00:03, 19.03it/s]\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [00:02<00:02, 19.56it/s]\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [00:02<00:02, 20.32it/s]\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [00:02<00:02, 20.57it/s]\n",
            " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [00:02<00:02, 20.87it/s]\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [00:03<00:02, 20.87it/s]\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [00:03<00:02, 20.95it/s]\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [00:03<00:01, 20.10it/s]\n",
            " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [00:03<00:01, 19.93it/s]\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [00:03<00:01, 20.25it/s]\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [00:03<00:01, 20.46it/s]\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [00:03<00:01, 20.56it/s]\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [00:04<00:01, 20.20it/s]\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [00:04<00:01, 20.00it/s]\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [00:04<00:00, 20.23it/s]\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [00:04<00:00, 20.01it/s]\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [00:04<00:00, 20.34it/s]\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [00:04<00:00, 20.36it/s]\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [00:04<00:00, 20.28it/s]\n",
            " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [00:05<00:00, 20.02it/s]\n",
            " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [00:05<00:00, 19.01it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.64it/s]\n",
            "\n",
            "\n",
            "Return code: 0\n",
            "\n",
            "‚úÖ Script completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Run measurement + build plots + write manifest (end-to-end)\n",
        "\n",
        "import glob\n",
        "import time\n",
        "\n",
        "run_started = time.time()\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    \"scripts/measure_sink_text.py\",\n",
        "    \"--task\",\n",
        "    TASK,\n",
        "    \"--split\",\n",
        "    SPLIT,\n",
        "    \"--model\",\n",
        "    MODEL,\n",
        "    \"--samples\",\n",
        "    str(SAMPLES),\n",
        "    \"--seed\",\n",
        "    str(SEED),\n",
        "    \"--sink_tokens\",\n",
        "    str(SINK_TOKENS),\n",
        "    \"--query_mode\",\n",
        "    QUERY_MODE,\n",
        "    \"--query_start\",\n",
        "    str(QUERY_START),\n",
        "    \"--chat\",\n",
        "    CHAT,\n",
        "    \"--device\",\n",
        "    DEVICE,\n",
        "    \"--quantization\",\n",
        "    QUANT,\n",
        "    \"--out_dir\",\n",
        "    str(DATA_DIR),\n",
        "]\n",
        "\n",
        "print(\"Running:\")\n",
        "print(\" \".join(cmd))\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "print(\"\\nSTDOUT:\\n\", result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"\\nSTDERR:\\n\", result.stderr)\n",
        "print(\"\\nReturn code:\", result.returncode)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    raise RuntimeError(\"measure_sink_text.py failed\")\n",
        "\n",
        "# Collect inputs\n",
        "inputs = sorted(glob.glob(str(DATA_DIR / \"*.jsonl.gz\")))\n",
        "meta = sorted(glob.glob(str(DATA_DIR / \"*.meta.json\")))\n",
        "print(\"\\nInputs:\")\n",
        "print(\"  jsonl.gz:\", len(inputs))\n",
        "print(\"  meta.json:\", len(meta))\n",
        "\n",
        "if not inputs:\n",
        "    raise RuntimeError(f\"No .jsonl.gz produced in {DATA_DIR}\")\n",
        "\n",
        "# Build plots (same as hypotheses/H0_sanity/scripts/run_plots.sh, but without uv)\n",
        "plot_jobs = [\n",
        "    (\"scripts/plot_accuracy_vs_sink_runs.py\", PLOTS_DIR / \"accuracy_vs_sink\", [\"--inputs\", *inputs]),\n",
        "    (\"scripts/plot_h1.py\", PLOTS_DIR / \"h1\", [\"--inputs\", *inputs, \"--label\", \"auto\"]),\n",
        "    (\"scripts/plot_h1_heatmap.py\", PLOTS_DIR / \"h1_heatmap\", [\"--inputs\", *inputs, \"--label\", \"auto\"]),\n",
        "    (\"scripts/plot_layer_profiles.py\", PLOTS_DIR / \"layers\", [\"--inputs\", *inputs]),\n",
        "    (\"scripts/plot_sink_entropy.py\", PLOTS_DIR / \"correlation\", [\"--inputs\", *inputs]),\n",
        "]\n",
        "\n",
        "for script, out_dir, extra_args in plot_jobs:\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    p_cmd = [sys.executable, script, \"--out_dir\", str(out_dir), *extra_args]\n",
        "    print(\"\\nPlot:\", \" \".join(p_cmd))\n",
        "    p = subprocess.run(p_cmd, capture_output=True, text=True)\n",
        "    if p.returncode != 0:\n",
        "        print(\"\\n--- plot stdout ---\\n\", p.stdout)\n",
        "        print(\"\\n--- plot stderr ---\\n\", p.stderr)\n",
        "        raise RuntimeError(f\"Plot failed: {script}\")\n",
        "\n",
        "# Manifest for reproducibility\n",
        "manifest = {\n",
        "    \"run_name\": RUN_NAME,\n",
        "    \"repo_url\": REPO_URL,\n",
        "    \"git_head\": GIT_HEAD,\n",
        "    \"started_ts\": run_started,\n",
        "    \"finished_ts\": time.time(),\n",
        "    \"cmd\": cmd,\n",
        "    \"params\": {\n",
        "        \"task\": TASK,\n",
        "        \"split\": SPLIT,\n",
        "        \"model\": MODEL,\n",
        "        \"samples\": SAMPLES,\n",
        "        \"seed\": SEED,\n",
        "        \"sink_tokens\": SINK_TOKENS,\n",
        "        \"query_mode\": QUERY_MODE,\n",
        "        \"query_start\": QUERY_START,\n",
        "        \"chat\": CHAT,\n",
        "        \"device\": DEVICE,\n",
        "        \"quantization\": QUANT,\n",
        "    },\n",
        "    \"outputs\": {\n",
        "        \"data_dir\": str(DATA_DIR),\n",
        "        \"plots_dir\": str(PLOTS_DIR),\n",
        "        \"meta_dir\": str(META_DIR),\n",
        "    },\n",
        "}\n",
        "\n",
        "(META_DIR / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "print(\"\\nSaved manifest:\", META_DIR / \"manifest.json\")\n",
        "print(\"\\nDONE. Results:\")\n",
        "print(\"  DATA_DIR:\", DATA_DIR)\n",
        "print(\"  PLOTS_DIR:\", PLOTS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta files: 1\n",
            "Data files: 1\n",
            "\n",
            "Run meta:\n",
            "{\n",
            "  \"task\": \"mmlu\",\n",
            "  \"dataset\": \"cais/mmlu\",\n",
            "  \"subset\": \"all\",\n",
            "  \"split\": \"test\",\n",
            "  \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
            "  \"revision\": null,\n",
            "  \"samples\": 100,\n",
            "  \"seed\": 42,\n",
            "  \"sink_tokens\": 4,\n",
            "  \"query_mode\": \"last\",\n",
            "  \"query_start\": 0,\n",
            "  \"chat\": \"auto\",\n",
            "  \"quantization\": \"none\",\n",
            "  \"device\": \"cuda\",\n",
            "  \"cuda_visible_devices\": null,\n",
            "  \"transformers_version\": \"4.57.6\",\n",
            "  \"torch_version\": \"2.9.0+cu126\",\n",
            "  \"timestamp\": 1769544172.8616776\n",
            "}\n",
            "\n",
            "üìä File size: 317122 bytes\n",
            "üìù Total lines in file: 100\n",
            "‚úÖ First row keys: ['chat_mode', 'correct', 'entropy', 'hallucinated', 'idx', 'label_hallucinated', 'meta', 'model', 'pred', 'quantization', 'query_mode', 'query_start', 'seq_len', 'sink_by_layer', 'sink_by_layer_head', 'sink_mass', 'sink_tokens', 'target', 'task']\n",
            "   Sample: sink_mass=0.39774010241741226, correct=True\n"
          ]
        }
      ],
      "source": [
        "# Quick sanity summary (read produced run file)\n",
        "\n",
        "import gzip\n",
        "\n",
        "jsonl_files = sorted(DATA_DIR.glob(\"*.jsonl.gz\"))\n",
        "meta_files = sorted(DATA_DIR.glob(\"*.meta.json\"))\n",
        "\n",
        "print(\"Meta files:\", len(meta_files))\n",
        "print(\"Data files:\", len(jsonl_files))\n",
        "\n",
        "if meta_files:\n",
        "    m = json.loads(meta_files[0].read_text())\n",
        "    print(\"\\nRun meta (from file):\")\n",
        "    print(json.dumps(m, indent=2))\n",
        "\n",
        "if not jsonl_files:\n",
        "    raise RuntimeError(\"No data files\")\n",
        "\n",
        "p = jsonl_files[0]\n",
        "print(\"\\nData file:\", p.name)\n",
        "print(\"Size:\", p.stat().st_size, \"bytes\")\n",
        "\n",
        "n = 0\n",
        "n_correct = 0\n",
        "sink_vals = []\n",
        "with gzip.open(p, \"rt\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        r = json.loads(line)\n",
        "        n += 1\n",
        "        if r.get(\"correct\") is True:\n",
        "            n_correct += 1\n",
        "        if r.get(\"sink_mass\") is not None:\n",
        "            sink_vals.append(float(r[\"sink_mass\"]))\n",
        "\n",
        "print(\"Rows:\", n)\n",
        "print(\"Accuracy (recomputed):\", (n_correct / n) if n else None)\n",
        "if sink_vals:\n",
        "    print(\"sink_mass range:\", (min(sink_vals), max(sink_vals)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Creating archive...\n",
            "‚¨áÔ∏è  Downloading h0_results.zip...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5ffc3703-5b17-4541-a975-5f27014f38d4\", \"h0_results.zip\", 317862)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Download started! Extract the zip and copy files to:\n",
            "   /Users/aeshef/Downloads/sinks/hypotheses/H0_sanity/data/\n"
          ]
        }
      ],
      "source": [
        "# Export results\n",
        "# - If USE_DRIVE=True: artifacts are already in Google Drive (no manual copy needed).\n",
        "# - If USE_DRIVE=False: create a zip and download once.\n",
        "\n",
        "import shutil\n",
        "\n",
        "archive_path = OUT_BASE / \"run_artifacts\"\n",
        "zip_file = shutil.make_archive(str(archive_path), \"zip\", str(OUT_BASE))\n",
        "print(\"Created:\", zip_file)\n",
        "\n",
        "if USE_DRIVE:\n",
        "    print(\"\\n‚úÖ Saved to Google Drive:\")\n",
        "    print(\"  \", OUT_BASE)\n",
        "    print(\"\\nYou can share this Drive folder with a collaborator.\")\n",
        "else:\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"\\n‚¨áÔ∏è Downloading zip...\")\n",
        "    files.download(zip_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Found h0_results.zip\n",
            "  ‚úì Extracted mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz\n",
            "  ‚úì Extracted mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.meta.json\n",
            "\n",
            "‚úÖ Files extracted to /content/sinks/sinks/sinks/hypotheses/H0_sanity/data\n",
            "\n",
            "üìã Next: Download files from Colab to your local machine\n",
            "   Use VS Code file sync or run the download cell below\n"
          ]
        }
      ],
      "source": [
        "# Reproducibility notes (for collaborators)\n",
        "\n",
        "print(\"How a collaborator reproduces this run:\")\n",
        "print(\"- open this notebook\")\n",
        "print(\"- keep the same CONFIG in cell 1\")\n",
        "print(\"- run all\")\n",
        "print(\"\\nWhat makes it reproducible:\")\n",
        "print(\"- fresh git clone + recorded git commit\")\n",
        "print(\"- saved META_DIR/manifest.json + META_DIR/pip_freeze.txt\")\n",
        "print(\"\\nWhere to look:\")\n",
        "print(\"- manifest:\", META_DIR / \"manifest.json\")\n",
        "print(\"- pip freeze:\", META_DIR / \"pip_freeze.txt\")\n",
        "print(\"- plots:\", PLOTS_DIR)\n",
        "print(\"- data:\", DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading individual files...\n",
            "  ‚¨áÔ∏è  mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz (317122 bytes)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e5ca5e33-6bf4-44cf-8e9a-f9843c0dfa61\", \"mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz\", 317122)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚¨áÔ∏è  mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.meta.json (442 bytes)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0b30cce1-59c6-4709-b8c7-a58f0ce38295\", \"mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.meta.json\", 442)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Download complete!\n",
            "\n",
            "üìã Instructions:\n",
            "   1. Files should download to your default Downloads folder\n",
            "   2. Copy them to: /Users/aeshef/Downloads/sinks/hypotheses/H0_sanity/data/\n",
            "   3. Or use VS Code file sync if available\n"
          ]
        }
      ],
      "source": [
        "# Optional: also write a short human-readable summary next to manifest\n",
        "\n",
        "summary = f\"\"\"# Run summary\n",
        "\n",
        "- run_name: {RUN_NAME}\n",
        "- git_head: {GIT_HEAD}\n",
        "- task: {TASK}\n",
        "- model: {MODEL}\n",
        "- split: {SPLIT}\n",
        "- samples: {SAMPLES}\n",
        "- seed: {SEED}\n",
        "- sink_tokens(K): {SINK_TOKENS}\n",
        "- query_mode(Q): {QUERY_MODE} (query_start={QUERY_START})\n",
        "- chat: {CHAT}\n",
        "- device: {DEVICE}\n",
        "- quantization: {QUANT}\n",
        "\n",
        "## Outputs\n",
        "- data: {DATA_DIR}\n",
        "- plots: {PLOTS_DIR}\n",
        "- meta: {META_DIR}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "(META_DIR / \"SUMMARY.md\").write_text(summary, encoding=\"utf-8\")\n",
        "print(\"Wrote:\", META_DIR / \"SUMMARY.md\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_47f52f6d-b3e5-4919-9c42-3889b2c45938\", \"mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.jsonl.gz\", 317122)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Deprecated: manual download helper (not needed)\n",
        "# Use cell 6 (Export results) instead.\n",
        "print(\"Deprecated cell: use Export results cell (cell 6).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/root/Downloads/mmlu__Qwen__Qwen2.5-0.5B-Instruct__K4__qlast.*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Deprecated: Colab cannot write to /Users/... (local Mac filesystem)\n",
        "# Use Google Drive (cell 1) or download the zip (cell 6).\n",
        "print(\"Deprecated cell: Colab FS can't access /Users/... .\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
