{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sinks: quickstart notebook\n",
        "\n",
        "This notebook is a scratchpad to run the **current reproducible pipeline**:\n",
        "- produce `artifacts/results/mmlu_accuracy_sink_*.json`\n",
        "- analyze correlations (`sink_mass`, `entropy`, `correct`)\n",
        "- build plots into `artifacts/plots/`\n",
        "\n",
        "> Note: running models requires a working `torch/transformers` setup and (ideally) a GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path | None = None) -> Path:\n",
        "    \"\"\"Find repo root by walking upwards until pyproject.toml is found.\"\"\"\n",
        "    p = (start or Path.cwd()).resolve()\n",
        "    for cur in [p, *p.parents]:\n",
        "        if (cur / \"pyproject.toml\").exists():\n",
        "            return cur\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find repo root (pyproject.toml not found). \"\n",
        "        \"Run the notebook from within the repo, or set REPO manually.\"\n",
        "    )\n",
        "\n",
        "\n",
        "REPO = find_repo_root()\n",
        "CONFIG_PATH = REPO / \"configs\" / \"mmlu_accuracy.json\"\n",
        "config = json.loads(CONFIG_PATH.read_text())\n",
        "config"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'task': 'mmlu_accuracy_sink',\n",
              " 'defaults': {'samples': 2000,\n",
              "  'sink_tokens': 4,\n",
              "  'chat': 'auto',\n",
              "  'quantization': 'none',\n",
              "  'device': 'cuda'},\n",
              " 'models': ['mistralai/Mistral-7B-v0.1',\n",
              "  'mistralai/Mistral-Nemo-Instruct-2407',\n",
              "  'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
              "  'Qwen/Qwen2.5-7B-Instruct',\n",
              "  'Qwen/Qwen2.5-14B-Instruct',\n",
              "  'Qwen/Qwen2.5-72B-Instruct']}"
            ]
          }
        }
      ],
      "id": "2deeab9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: run a *small* smoke test (few samples) to verify everything works.\n",
        "# Adjust model / samples depending on your hardware.\n",
        "#\n",
        "# Note: If `uv` is not available inside your Jupyter kernel PATH,\n",
        "# we fall back to running via the current Python interpreter.\n",
        "\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "\n",
        "def run_python(script: Path, args: list[str]):\n",
        "    uv = shutil.which(\"uv\")\n",
        "    if uv:\n",
        "        cmd = [uv, \"run\", \"python\", str(script), *args]\n",
        "    else:\n",
        "        cmd = [sys.executable, str(script), *args]\n",
        "    print(\"CMD:\", \" \".join(cmd))\n",
        "    return subprocess.run(cmd, cwd=str(REPO), check=False)\n",
        "\n",
        "\n",
        "model = config[\"models\"][0]\n",
        "args = [\n",
        "    \"--model\",\n",
        "    model,\n",
        "    \"--samples\",\n",
        "    \"20\",\n",
        "    \"--sink_tokens\",\n",
        "    str(config[\"defaults\"][\"sink_tokens\"]),\n",
        "    \"--chat\",\n",
        "    config[\"defaults\"][\"chat\"],\n",
        "]\n",
        "\n",
        "print(\"REPO:\", REPO)\n",
        "run_python(REPO / \"scripts\" / \"measure_accuracy.py\", args)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPO: /Users/aeshef/Downloads/sinks\n",
            "uv run python /Users/aeshef/Downloads/sinks/scripts/measure_accuracy.py --model mistralai/Mistral-7B-v0.1 --samples 20 --sink_tokens 4 --chat auto\n"
          ]
        },
        {
          "output_type": "error"
        }
      ],
      "id": "6a0c9d0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze all existing results + build the main comparison plot\n",
        "\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "\n",
        "def run_python(script: Path, args: list[str] | None = None):\n",
        "    args = args or []\n",
        "    uv = shutil.which(\"uv\")\n",
        "    if uv:\n",
        "        cmd = [uv, \"run\", \"python\", str(script), *args]\n",
        "    else:\n",
        "        cmd = [sys.executable, str(script), *args]\n",
        "    print(\"CMD:\", \" \".join(cmd))\n",
        "    return subprocess.run(cmd, cwd=str(REPO), check=False)\n",
        "\n",
        "\n",
        "run_python(REPO / \"scripts\" / \"analyze_mmlu_results.py\")\n",
        "run_python(REPO / \"scripts\" / \"compare_accuracy_sink.py\")\n",
        "print(\"Plots:\", REPO / \"artifacts\" / \"plots\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ac4544c1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}